{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP sur les données blablacar\n",
    "\n",
    "**Ce fichier est le fichier de travail**, l'autre fichier blablacar.ipynb est donné pour information et pour montrer comment les données ont été collectées. L'API blablacar permet de récupérer l'offre de transport sur la plateforme à partir de requêtes.\n",
    "\n",
    "\n",
    "Vous aurez besoin des fichiers correspondant à des récupérations de données aux mois de septembre et novembre:\n",
    "les fichiers ```blablacar_pp_sept.pkl``` et ```blablacar_pp_nov.pkl``` sont disponibles dans le répertoire ```ressources```.\n",
    "\n",
    "\n",
    "Ces fichiers correspondent à des requêtes à partir des villes suivantes:\n",
    ">  villes = ['Paris', 'Marseille', 'Grenoble', 'Lille', 'Strasbourg', 'Nantes', 'Bordeaux']\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mise à jour des librairies pour qu'on travaille tous dans le même environnement\n",
    "# (en commentaire pour ne pas le faire chaque fois)\n",
    "#! pip install numpy --upgrade\n",
    "#! pip install matplotlib --upgrade\n",
    "#! pip install pandas --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des données\n",
    "\n",
    "Les données numpy sont stockées au format pickle (code fourni ci-dessous):\n",
    "\n",
    "1. Importer le module : import `pickle as pkl`\n",
    "1. Charger les données avec `load`\n",
    "1. La structure est un dictionnaire, les données sont dans le champ `data`\n",
    "1. La description des colonnes est dans `indexcol`\n",
    "\n",
    "Les lignes suivantes permettent de décomposer la structure de données pour accéder à toutes les informations utiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 ['annee', 'mois', 'jour', 'heure', 'dep_ville', 'arr_ville', 'dep_coord_x', 'dep_coord_y', 'arr_coord_x', 'arr_coord_y', 'prix', 'marque', 'stars_confort', 'distance']\n",
      "(6428, 14)\n",
      "{'FORD': 6, 'BMW': 12, 'ISUZU': 32, 'OPEL': 1, 'LAND ROVER': 28, 'LIDER': 33, 'DS': 2, 'AUDI': 49, 'DACIA': 45, 'JAGUAR': 39, 'TOYOTA': 13, 'SUZUKI': 20, 'HUNDAI': 42, 'CITROEN': 17, 'IVECO': 8, 'RENAULT': 15, 'SKODA': 27, 'ROVER': 19, 'MITSUBISHI': 5, 'MERCEDES-BENZ': 35, 'DODGE': 29, 'ALFA ROMEO': 37, 'CHEVROLET': 26, 'LANCIA': 10, 'INFINITI': 36, 'DAEWOO': 30, 'MIETWAGEN': 38, 'VOLKSWAGEN': 3, 'LADA': 0, 'GOLF': 4, 'PORSCHE': 23, 'NISSAN': 40, 'unknown': 43, 'SSANGYONG': 34, 'FIAT': 50, 'SAAB': 14, 'CHRYSLER': 51, 'JEEP': 9, 'TESLA': 47, 'PEUGEOT': 25, 'MERCEDES BENZ': 48, 'MAZDA': 31, 'HONDA': 53, 'RANGE ROVER': 11, 'SMART': 24, 'KIA': 52, 'VOLVO': 46, 'LEXUS': 44, 'SUBARU': 18, 'SEAT': 16, 'MINI': 7, 'SUV LEXUS': 21, 'MERCEDES': 41, 'HYUNDAI': 22}\n",
      "{6: 'FORD', 12: 'BMW', 32: 'ISUZU', 1: 'OPEL', 28: 'LAND ROVER', 33: 'LIDER', 2: 'DS', 49: 'AUDI', 45: 'DACIA', 39: 'JAGUAR', 13: 'TOYOTA', 20: 'SUZUKI', 42: 'HUNDAI', 17: 'CITROEN', 8: 'IVECO', 15: 'RENAULT', 27: 'SKODA', 19: 'ROVER', 5: 'MITSUBISHI', 35: 'MERCEDES-BENZ', 29: 'DODGE', 37: 'ALFA ROMEO', 26: 'CHEVROLET', 10: 'LANCIA', 36: 'INFINITI', 30: 'DAEWOO', 38: 'MIETWAGEN', 3: 'VOLKSWAGEN', 0: 'LADA', 4: 'GOLF', 23: 'PORSCHE', 40: 'NISSAN', 43: 'unknown', 34: 'SSANGYONG', 50: 'FIAT', 14: 'SAAB', 51: 'CHRYSLER', 9: 'JEEP', 47: 'TESLA', 25: 'PEUGEOT', 48: 'MERCEDES BENZ', 31: 'MAZDA', 53: 'HONDA', 11: 'RANGE ROVER', 24: 'SMART', 52: 'KIA', 46: 'VOLVO', 44: 'LEXUS', 18: 'SUBARU', 16: 'SEAT', 7: 'MINI', 21: 'SUV LEXUS', 41: 'MERCEDES', 22: 'HYUNDAI'}\n"
     ]
    }
   ],
   "source": [
    "# chargement des données numpy\n",
    "fich = pkl.load( open('blablacar_pp_sept.pkl', 'rb'))\n",
    "# ou fich = pkl.load( open('ressources/blablacar_pp_sept.pkl', 'rb'))\n",
    "\n",
    "# {'indexcol': cols , 'data':pp2db, 'villes': villes, 'marques':marques }\n",
    "titles_col = fich['indexcol'] # titre des colonnes\n",
    "print(len(titles_col), titles_col) \n",
    "data = fich['data'] # matrice de données\n",
    "print(data.shape)\n",
    "dico_villes = fich['villes'] # dictionnaire des villes\n",
    "inv_dico_villes = dict(zip(dico_villes.values(), dico_villes.keys()))\n",
    "dico_marques = fich['marques'] # dictionnaires des marques\n",
    "inv_dico_marques = dict(zip(dico_marques.values(), dico_marques.keys()))\n",
    "print(dico_marques)\n",
    "print(inv_dico_marques)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Passage au format pandas\n",
    "\n",
    "Le code de transformation des données au format pandas est fourni. Ainsi, dans la suite de cet énoncé, vous aurez sous la main les deux formats `numpy` et `pandas`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)\n",
    "df.columns = titles_col\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LADA',\n",
       " 'OPEL',\n",
       " 'DS',\n",
       " 'VOLKSWAGEN',\n",
       " 'GOLF',\n",
       " 'MITSUBISHI',\n",
       " 'FORD',\n",
       " 'MINI',\n",
       " 'IVECO',\n",
       " 'JEEP',\n",
       " 'LANCIA',\n",
       " 'RANGE ROVER',\n",
       " 'BMW',\n",
       " 'TOYOTA',\n",
       " 'SAAB',\n",
       " 'RENAULT',\n",
       " 'SEAT',\n",
       " 'CITROEN',\n",
       " 'SUBARU',\n",
       " 'ROVER',\n",
       " 'SUZUKI',\n",
       " 'SUV LEXUS',\n",
       " 'HYUNDAI',\n",
       " 'PORSCHE',\n",
       " 'SMART',\n",
       " 'PEUGEOT',\n",
       " 'CHEVROLET',\n",
       " 'SKODA',\n",
       " 'LAND ROVER',\n",
       " 'DODGE',\n",
       " 'DAEWOO',\n",
       " 'MAZDA',\n",
       " 'ISUZU',\n",
       " 'LIDER',\n",
       " 'SSANGYONG',\n",
       " 'MERCEDES-BENZ',\n",
       " 'INFINITI',\n",
       " 'ALFA ROMEO',\n",
       " 'MIETWAGEN',\n",
       " 'JAGUAR',\n",
       " 'NISSAN',\n",
       " 'MERCEDES',\n",
       " 'HUNDAI',\n",
       " 'unknown',\n",
       " 'LEXUS',\n",
       " 'DACIA',\n",
       " 'VOLVO',\n",
       " 'TESLA',\n",
       " 'MERCEDES BENZ',\n",
       " 'AUDI',\n",
       " 'FIAT',\n",
       " 'CHRYSLER',\n",
       " 'KIA',\n",
       " 'HONDA']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Illustration du passage des marques (difficiles à manipuler) à des numéros et inversement\n",
    "\n",
    "nums = list(inv_dico_marques.keys())\n",
    "nums.sort() # remise dans l'ordre\n",
    "\n",
    "[inv_dico_marques[i] for i in nums]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question optionnelle (assez difficile) \n",
    "\n",
    "On remarque que les données ne sont pas propres au niveau des marques: proposer une technique pour mettre au propre le tableau et enlever les doublons. \n",
    "\n",
    "Une méthode consiste à identifier les doublons à la main et les fusionner. Une autre approche consiste à calculer des distances d'édition entre les marques et à mettre des seuils :\n",
    "```\n",
    "import Levenshtein\n",
    "mot1 = \"chat\"\n",
    "mot2 = \"chien\"\n",
    "distance = Levenshtein.distance(mot1, mot2)\n",
    "print(\"Distance d'édition :\", distance)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1: Mise en forme pandas\n",
    "[question indépendante de la suite]\n",
    "\n",
    "Les colonnes ville (arrivée & départ) et marque correspondent à des indices. Nous voulons ajouter 3 colonnes dans la structure de données `pandas` avec le nom des villes et le nom des marques. Ces données sont disponibles dans les dictionnaires (`inv_dico_marques` et `inv_dico_villes`) python chargés au début du fichier.\n",
    "\n",
    "Les 3 colonnes seront nommées:\n",
    "* dep_ville_nom\n",
    "* arr_ville_nom\n",
    "* marque_nom\n",
    "\n",
    "***Aide:*** Attention à bien convertir les clés en entier, les réels ne sont pas tolérés.\n",
    "Pour récupérer la marque de la voiture correspondant au premier trajet:\n",
    "```python\n",
    "print(inv_dico_marques[int(df['marque'][0])])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(inv_dico_marques[int(df['marque'][0])])\n",
    "\n",
    "# réponse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2 : Discrétisation et histogramme\n",
    "\n",
    "Nous nous intéressons à la variable `distance` (dernière colonne de la structure `numpy`). Nous allons procéder de la manière suivante:\n",
    "1. Analyse rapide de la variable aléatoire: calcul de la moyenne et de l'écart-type\n",
    "1. Analyse plus fine (1): affichage des 10 déciles de la variable\n",
    "1. Analyse plus fine (2): discrétisation de la variable en 10 intervalles de largeur constante & comptage des effectifs dans chaque catégorie (= construction d'un histogramme)\n",
    "1. Discuter le nombre d'intervalles pour l'histogramme et trouver une valeur satisfaisante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse rapide : moyenne, écart-type, calcul des quantiles pour faire la synthèse de cette variable aléatoire\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discrétisation des distances & histogramme\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3 : enrichissement et histogramme \n",
    "\n",
    "Ajouter une variable `prix_km` dans votre structure de données (`numpy` ou `pandas`)\n",
    "\n",
    "Tracer l'histogramme des prix au km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# réponse\n",
    "# construction des prix au km\n",
    "\n",
    "\n",
    "# histogramme des prix au km\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4: Distributions jointes\n",
    "\n",
    "Nous voulons maintenant étudier la distribution jointe entre les prix au km et la marque de la voiture. Partir des distributions discétisées et construire le tableau d'effectif puis normaliser par les effectifs de l'échantillon pour estimer la loi jointe.\n",
    "\n",
    "1. Il semble que quelques points abbérants faussent notre histogramme. Nous proposons (arbitrairement) de seuiller toutes les valeurs au dessus du 99ème percentiles à la valeur du 99ème percentile. Vous pouvez tracer à nouveau l'histogramme pour voir la différence.\n",
    "**Note:** il s'agit d'une normalisation très classique en analyse de données. On peut seuiller ou éliminer les données qui semblent abérrantes.\n",
    "\n",
    "1. Discrétiser les prix au km en 30 catégories.\n",
    "1. Compter les effectifs pour chaque marque et chaque catégorie de prix. Normaliser ensuite par l'effectif pour obtenir un tableau homogène à une loi jointe (ie sommant à 1).<BR>\n",
    "**Note:** il peut être plus facile de travailler sur la colonne marque (indice) plutôt que sur les chaines de caractères.    \n",
    "**Note 2/rappel:** les indices dans une matrice doivent toujours être entiers. `int(...)` \n",
    "Si vos données sont réelles, il faut donc faire: `mat[int(data[...])]` pour accéder à la case de la matrice\n",
    "\n",
    "1. Afficher ensuite la distribution jointe\n",
    "**Rappel:** \n",
    "pour ajouter une description sur l'axe des x:\n",
    "```python\n",
    "fig, ax = plt.subplots(1,1)\n",
    "plt.imshow(p_PM, interpolation='nearest')\n",
    "ax.set_xticks(np.arange(len(dico_marques)))\n",
    "ax.set_xticklabels(dico_marques.keys(),rotation=90,fontsize=8)\n",
    "plt.show()\n",
    "```\n",
    "- Si l'image est trop petite pour voir quelque chose: solution = sauvegarde en pdf (ie vectorielle) + ouverture avec un logiciel de lecture pdf\n",
    "```python\n",
    "plt.savefig('mafigure.pdf')\n",
    "```\n",
    "\n",
    "1. [OPTION] la variable `marque` est bruitée. Vous pourrez vous amuser à éliminer ou fusionner certaines catégories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# réponse\n",
    "Np=30\n",
    "\n",
    "# elimination des valeurs aberrantes\n",
    "\n",
    "\n",
    "# tracé du nouvel histogramme\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# réponse\n",
    "\n",
    "# ajout de la catégorie de prix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# réponse\n",
    "# Np =30 déjà défini\n",
    "Nm = len(dico_marques) # => ne pas mettre ces chiffres en dur ci-dessous => illisble\n",
    "\n",
    "# calcul des probabilites jointes (Prix, Marque)\n",
    "\n",
    "p_PM = np.zeros((Np,Nm))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5 : Distributions conditionnelles\n",
    "\n",
    "Il est diffile d'analyser la probabilité jointe... Nous allons donc passer à la loi conditionnelle: nous voulons donc calculer la probabilité du prix au km conditionnellement à la marque de la voiture.\n",
    "\n",
    "1. Calculer `p_P_M`\n",
    "1. Proposer un critère rapide pour vérifier que votre distribution conditionnelle respecte bien les propriétés de base\n",
    "1. Dans le cas où les données de marques n'ont pas été nettoyées, cette distribution conditionnelle fait apparaitre des pics très marqués: à quoi correspondent ces pics? Pouvons-nous tirer parti de ces informations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loi conditionnelle distance | marque\n",
    "\n",
    "# calcul de la marginale sur les marques\n",
    "\n",
    "# calcul de la loi conditionnelle\n",
    "\n",
    "# critère rapide pour vérifier que la loi conditionnelle est bien formattée:\n",
    "\n",
    "# affichage de la loi conditionnelle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Réponse (à quoi correspondent ces pics)\n",
    "\n",
    "votre réponse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q6: Tracé de l'ensemble de l'échantillon avec des codes couleurs\n",
    "\n",
    "Nous proposons ensuite de tracer toutes les trajectoires des voitures blablacar. Pour cela, il faut utiliser la commande `plt.plot`.\n",
    "Vous devez visualiser des trajectoires en étoiles à partir des 7 villes requêtes: `['Paris', 'Marseille', 'Grenoble', 'Lille', 'Strasbourg', 'Nantes', 'Bordeaux']`.\n",
    "\n",
    "1. [NE PAS FAIRE] Dans un premier temps, il est possible de donner toutes les coordoonées de toutes les trajectoires... Attention à l'ordre des arguments dans le plot:\n",
    "```plt.plot(tous_les_x, tous_les_y)```\n",
    "Afin de tracer des trajectoires, il faut envoyer les x et les y 2 par 2 dans une boucle `for` <BR>\n",
    "C'est très long et pas très joli...\n",
    "\n",
    "1. Pour éviter les boucles, il existe une méthode `quiver` dédiée au tracé de champs de vecteurs: ça ira beaucoup plus vite qu'avec plot. Il faut juste bien comprendre les mécanismes d'échelles. Pour utiliser l'échelle 1, la commande est la suivante:\n",
    "```python\n",
    "plt.quiver(x_dep, y_dep, delta_x, delta_y,\\\n",
    "            angles='xy', scale_units='xy', scale=1)\n",
    "```\n",
    "Rappel: les noms les colonnes utiles sont: `dep_coord_x, dep_coord_y, arr_coord_x, arr_coord_y` <BR>\n",
    "Cette approche est rapide à coder (une ligne) et rapide à exécuter (1 seconde)... Mais le résultat n'est pas très beau.\n",
    "\n",
    "1. Isoler les trajets proposés à partir de chacune des villes sachant que leurs coordonnées sont:\n",
    "```python\n",
    "coord = np.array([[45.18721767,  5.72345183],\n",
    " [47.22572172, -1.56558993],\n",
    " [50.63010695,  3.07071992],\n",
    " [48.5782548,   7.74078742],\n",
    " [44.83848889, -0.58156509],\n",
    " [43.2991509,   5.38925024],\n",
    " [48.8477201,   2.34607889]])\n",
    "```\n",
    "Chaque trajectoire (point de départ) sera rattachée à la ville la plus proche.\n",
    "Une fois la distance calculée pour chaque origine de trajectoire, vous pourrez avoir besoin de `argmin`\n",
    "1. Tracer les trajets d'une couleur spéciale en fonction des origines. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tracé de l'ensemble des trajectoires => moche et lent\n",
    "\n",
    "plt.figure()\n",
    "for t in data:\n",
    "    plt.plot(t[[6,8]], t[[7,9]]) # dans les données au format numpy\n",
    "    \n",
    "plt.show()\n",
    "\n",
    "# note le code couleur est arbitraire: matplot lib change de couleur à chaque passage dans la boucle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avec quiver\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avec quiver et des couleur\n",
    "\n",
    "# 1 recherche de la ville la plus proche du point de départ\n",
    "coord = np.array([[45.18721767,  5.72345183],\n",
    " [47.22572172, -1.56558993],\n",
    " [50.63010695,  3.07071992],\n",
    " [48.5782548,   7.74078742],\n",
    " [44.83848889, -0.58156509],\n",
    " [43.2991509,   5.38925024],\n",
    " [48.8477201,   2.34607889]])\n",
    "\n",
    "dep = np.vstack((df['dep_coord_x'], df['dep_coord_y'])).T\n",
    "print(dep[0]) # coordonnée de la première ville\n",
    "\n",
    "# calcul des distances => A vous de jouer\n",
    "dist = \n",
    "\n",
    "print(dist[0]) # distance du premier point aux 7 villes de référence\n",
    "\n",
    "# trouver la ville la plus proche (argmin)\n",
    "ind_ville = \n",
    "\n",
    "print(np.unique(ind_ville)) # vérifier que toutes les villes sont au moins sélectionnées une fois\n",
    "\n",
    "# affichage\n",
    "couleurs = ['r', 'g', 'b', 'y', 'm', 'k', 'c']\n",
    "\n",
    "plt.figure()\n",
    "for ind in range(len(coord)): # pour chaque ville\n",
    "    index  = ... # recherche des indices dans le tableau correspondant à la ville ind\n",
    "    \n",
    "    plt.quiver(df['dep_coord_x'].values[index], df['dep_coord_y'].values[index],\\\n",
    "           (df['arr_coord_x']-df['dep_coord_x']).values[index], (df['arr_coord_y']-df['dep_coord_y']).values[index],\\\n",
    "         angles='xy', scale_units='xy', scale=1, color = couleurs[ind])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q7: Etude de la corrélation entre variables\n",
    "\n",
    "On propose d'étudier la corrélation entre la distance du trajet et le nombre d'étoiles de confort. Attention, les étoiles ne sont pas toujours renseignées (-1 = inconnu). On fera aussi ces opérations entre la distance et le prix.\n",
    "\n",
    "1. Tracer dans le plan les coordonnées (distance,etoile) pour les points concernés (ie en éliminant les points sans information sur les étoiles)\n",
    "\n",
    "Vous utiliserez la commande `scatter` pour réaliser l'opération\n",
    "1. Calculer le coefficient de corrélation entre les deux variables aléatoires\n",
    "\n",
    "1. refaire les mêmes opérations pour le deuxième couple de variables aléatoires\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test de corrélation entre la distance et le confort de la voiture\n",
    "\n",
    "# coef\n",
    "\n",
    "\n",
    "\n",
    "# test de corrélation entre la distance et le prix\n",
    "\n",
    "# coef\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Q8 : partie optionnelle\n",
    "\n",
    "Comparer les données de septembre et de novembre. Chercher les points communs et les différences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
